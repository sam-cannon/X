{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "\n",
    "from googletrans import Translator\n",
    "import copy\n",
    "import subprocess\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Significant Experiments For Products\n",
    "- __Now I will be separating each product out by its platform, as well as by the NPS question__\n",
    "    - If a product contains BOTH a question about O365 Suite (i.e.\"How likely are you to recommend O365 to a friend?\") AND tha specific product (i.e. \"How likely are you to recommend Word to a friend?\") then that product will be separated out as such\n",
    "    - If the product does not have both questions then it will be left with one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (8,30,170,181,205) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished importing chunk 1\n",
      "finished importing chunk 2\n",
      "finished importing chunk 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (30,170,181) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished importing chunk 4\n",
      "finished importing chunk 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (170,181) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished importing chunk 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (8,30,170,181,205,357) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished importing chunk 7\n",
      "finished importing chunk 8\n",
      "finished importing chunk 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (30,170,181,357) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished importing chunk 10\n",
      "finished importing chunk 11\n",
      "finished importing chunk 12\n",
      "finished importing chunk 13\n",
      "finished importing chunk 14\n",
      "finished importing chunk 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (8,170,181,205) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished importing chunk 16\n",
      "finished importing chunk 17\n",
      "finished importing chunk 18\n",
      "finished importing chunk 19\n",
      "finished importing chunk 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (170,181,357) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished importing chunk 21\n",
      "finished importing chunk 22\n",
      "finished importing chunk 23\n",
      "finished importing chunk 24\n",
      "finished importing chunk 25\n",
      "finished importing chunk 26\n",
      "finished importing chunk 27\n",
      "finished importing chunk 28\n",
      "finished importing chunk 29\n",
      "finished importing chunk 30\n",
      "finished importing chunk 31\n",
      "finished importing chunk 32\n",
      "finished importing chunk 33\n",
      "finished importing chunk 34\n",
      "finished importing chunk 35\n",
      "finished importing chunk 36\n",
      "finished importing chunk 37\n",
      "finished importing chunk 38\n",
      "finished importing chunk 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (8,30,170,205) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished importing chunk 40\n",
      "finished importing chunk 41\n",
      "finished importing chunk 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (8,30,170,181,205,356) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished importing chunk 43\n",
      "finished importing chunk 44\n",
      "finished importing chunk 45\n",
      "finished importing chunk 46\n",
      "finished importing chunk 47\n",
      "finished importing chunk 48\n",
      "finished importing chunk 49\n",
      "finished importing chunk 50\n",
      "finished importing chunk 51\n",
      "finished importing chunk 52\n",
      "finished importing chunk 53\n",
      "finished importing chunk 54\n",
      "finished importing chunk 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (8,170,181,205,254,268,275,278,280,300,311,317,325,361) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished importing chunk 56\n",
      "finished importing chunk 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (8,170,181,205,357) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished importing chunk 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (8,170,181,205,254) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished importing chunk 59\n",
      "finished importing chunk 60\n",
      "finished importing chunk 61\n",
      "finished importing chunk 62\n",
      "finished importing chunk 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (8,205) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished importing chunk 64\n"
     ]
    }
   ],
   "source": [
    "#in order to separate products by NPS question, I need to re-import the data adding in the actual questions\n",
    "#set proper working directors\n",
    "os.chdir('C:\\\\Users\\\\paperspace\\\\Desktop\\\\Microsoft\\\\AB Testing')\n",
    "\n",
    "#import data (only first n00k rows as a sample)\n",
    "chunksize = 100000\n",
    "df = pd.read_csv('end_user_nps_cy2020_only_e-exp_partial.tsv', delimiter = '\\t', chunksize = chunksize)\n",
    "\n",
    "#read in dataset that contains column names\n",
    "colnames = pd.read_excel('sample_AB.xlsx', nrows = 1)\n",
    "\n",
    "df.columns = colnames.columns\n",
    "\n",
    "#read in df by chunks\n",
    "chunks = []\n",
    "for idx, chunk in enumerate(df):\n",
    "    chunk.columns = colnames.columns\n",
    "    chunk = chunk[['XpId', 'XpGroupType', 'XpUrl', 'Id','SurveyId', 'SurveyRatingQuestion', 'SurveyType', 'SurveyRating', 'SurveyStartDate', \n",
    "                   'ProcessSessionId', 'Platform', 'Product', 'OcvLanguage', 'ClientSubmitTime']]\n",
    "    chunks.append(chunk)\n",
    "    print(f'finished importing chunk {idx + 1}')\n",
    "\n",
    "#concatenate chunks in list, have to pass sort=False to ignore the FutureWarning produced by this\n",
    "df = pd.concat(chunks, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Logit_Regression_df_with_separate_NPS_questions.csv', index = False)\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\paperspace\\\\Desktop\\\\Microsoft\\\\AB Testing')\n",
    "df = pd.read_csv('Logit_Regression_df_with_separate_NPS_questions.csv')\n",
    "\n",
    "#since these questions are all in different languages, and some of the questions are worded differently, I am going to simply filter them by \"Office 365\" and the name of the\n",
    "#individual product -- even when this question is in different languages, the name must be in there still hopefully\n",
    "questions = pd.DataFrame(df['SurveyRatingQuestion'].value_counts()).reset_index().rename(columns = {'index':'Question'})\n",
    "\n",
    "questions.to_csv('foreign_questions.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Languages\n",
    "- __So... there are several different languages that NPS questions were asked in for these surveys. I am going to translate these to English using Google Translate, then merge them back into the whole data set so that I can sort out specific app vs 0ffice 365 Suite questions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Google Translate to translate foreign language questions into english (this may not work on some VPNs, so if you are having trouble with this\n",
    "# then I recommend you change VPNs)\n",
    "def translate_text(text, dest_language=\"en\"):\n",
    "        # Used to translate using the googletrans library\n",
    "    import json\n",
    "    translator = Translator()\n",
    "    try:\n",
    "        translation = translator.translate(text=text, dest=dest_language)\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        # api call restriction\n",
    "        process = subprocess.Popen([\"nordvpn\", \"d\"], stdout=subprocess.PIPE)\n",
    "        process.wait()\n",
    "        process = subprocess.Popen([\"nordvpn\", \"c\", \"canada\"], stdout=subprocess.PIPE)\n",
    "        process.wait()\n",
    "        return Process_Data.translate_text(text=text, dest_language=dest_language)\n",
    "    return translation\n",
    "\n",
    "#translate all questions\n",
    "question_list = [x for x in questions.Question]\n",
    "\n",
    "translated_questions = [translate_text(x).text for x in question_list]\n",
    "\n",
    "questions.insert(loc = 1, column = 'TranslatedQuestions', value = [question for question in translated_questions])\n",
    "\n",
    "questions.to_csv('translated_quwstions_from_NPS_survey.csv', index = False)\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\paperspace\\\\Desktop\\\\Microsoft\\\\AB Testing\\\\Logistic Regression')\n",
    "translated_questions = pd.read_csv('translated_questions_from_NPS_survey.csv').drop('SurveyRatingQuestion', axis = 1) \\\n",
    "                                            .rename(columns = {'TranslatedQuestions':'TranslatedQuestion'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>TranslatedQuestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>Mennyire valószínű, hogy ajánlja a Outlook-öt másoknak, ha a véleményét kérnék?</td>\n",
       "      <td>How likely are you to recommend your Outlook or five others when I need a review?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>À quelle fréquence recommanderiez-vous Outlook à d’autres personnes si vous y êtes invité ?</td>\n",
       "      <td>How would you recommend Outlook frequency to others if prompted?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>¿Qué probabilidades hay de que recomiendes Outlook a otras personas si te preguntan?</td>\n",
       "      <td>What are the odds of you refer Outlook to others if they ask?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>¿Qué probabilidades hay de que recomiende Outlook a otras personas si le preguntaran?</td>\n",
       "      <td>What are the odds Outlook to recommend to others if asked?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>Hur troligt är det att du skulle rekommendera Outlook för andra, om du fick frågan?</td>\n",
       "      <td>How likely is it that you would recommend Outlook for others, if you were asked?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Question  \\\n",
       "561  Mennyire valószínű, hogy ajánlja a Outlook-öt másoknak, ha a véleményét kérnék?               \n",
       "562  À quelle fréquence recommanderiez-vous Outlook à d’autres personnes si vous y êtes invité ?   \n",
       "563  ¿Qué probabilidades hay de que recomiendes Outlook a otras personas si te preguntan?          \n",
       "564  ¿Qué probabilidades hay de que recomiende Outlook a otras personas si le preguntaran?         \n",
       "565  Hur troligt är det att du skulle rekommendera Outlook för andra, om du fick frågan?           \n",
       "\n",
       "                                                                    TranslatedQuestion  \n",
       "561  How likely are you to recommend your Outlook or five others when I need a review?  \n",
       "562  How would you recommend Outlook frequency to others if prompted?                   \n",
       "563  What are the odds of you refer Outlook to others if they ask?                      \n",
       "564  What are the odds Outlook to recommend to others if asked?                         \n",
       "565  How likely is it that you would recommend Outlook for others, if you were asked?   "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_questions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging translated questions into original df, dropping redundant question column \n",
    "df = translated_questions.join(df.set_index(df.SurveyRatingQuestion), on = 'Question').drop(['Question'], axis = 1)\n",
    "\n",
    "#searching for keywords in the df and separating products out by keyword -- this generates some duplicates becuase some questions include BOTH the\n",
    "# name of an app (i.e. Word) AND the word \"app\" as well, so we need to filter out duplicates with boolean logic after concatenating all of them, then filter \n",
    "# -- Therea are about 20 surveys that we will not capture filtering out in this manner that refer to \"games\" or other things that were simply lost in \n",
    "#translation and unable to be tied back to a specific product\n",
    "products = ['365|Office|office', \n",
    "            \"application|apli|App|app\", \n",
    "            'Word|word', 'Excel|excel', \n",
    "            'Powerpoint|powerpoint|PowerPoint', 'Outlook|outlook', 'Access|access', 'Visi|visi', \n",
    "            'OneNote', 'program', 'Proj|proj']\n",
    "\n",
    "d = {}\n",
    "for name in products:\n",
    "    d[name] = pd.DataFrame(df[(df['TranslatedQuestion'].astype(str).str.contains(f'{name}')) | (df['SurveyRatingQuestion'].astype(str).str.contains(f'{name}'))])\n",
    "\n",
    "#concatenating dfs together to see exactly how many survey responses we didn't capture using the above filtering\n",
    "dfs = []\n",
    "for x in d.keys():\n",
    "    prod = pd.DataFrame(d[x])\n",
    "    dfs.append(prod)\n",
    "\n",
    "    \n",
    "nps_df = pd.concat(dfs, axis = 0).drop_duplicates()\n",
    "\n",
    "#filter out cases that have NPS questions pertaining to the suite and speicific apps\n",
    "suite = nps_df[nps_df['TranslatedQuestion'].str.contains('365|Office|office|offi|ofi')]\n",
    "\n",
    "app = nps_df[~nps_df.index.isin(suite.index)]\n",
    "\n",
    "#add in a tag \n",
    "suite.insert(loc = 0, column = 'NPS Tag', value = 'O365 Suite')\n",
    "app.insert(loc = 0, column = 'NPS Tag', value = 'App')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6303374, 6303393)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looks like we are in fact only missing 19 columns\n",
    "nps_df.shape[0], df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TranslatedQuestion</th>\n",
       "      <th>XpId</th>\n",
       "      <th>XpGroupType</th>\n",
       "      <th>XpUrl</th>\n",
       "      <th>Id</th>\n",
       "      <th>SurveyId</th>\n",
       "      <th>SurveyRatingQuestion</th>\n",
       "      <th>SurveyType</th>\n",
       "      <th>SurveyRating</th>\n",
       "      <th>SurveyStartDate</th>\n",
       "      <th>ProcessSessionId</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Product</th>\n",
       "      <th>OcvLanguage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>How likely are you to recommend this game to a friend or colleague?</td>\n",
       "      <td>26895</td>\n",
       "      <td>C</td>\n",
       "      <td>https://ecs.skype.com/?page=ExperimentPage&amp;id=26895</td>\n",
       "      <td>flnps_v2_74d1be15b59a5601a2214a45e313c698</td>\n",
       "      <td>265d54ad-beff-47a1-85c4-2255f0bfee1e</td>\n",
       "      <td>Колика је вероватноћа да ћете ову апликацију препоручити пријатељу или колеги?</td>\n",
       "      <td>NpsStatic</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2/1/2018 12:00:00 AM</td>\n",
       "      <td>517e63f0-5a39-43ed-8f08-96d8e100174e</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>Desktop Word</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      TranslatedQuestion  \\\n",
       "443  How likely are you to recommend this game to a friend or colleague?   \n",
       "\n",
       "      XpId XpGroupType                                                XpUrl  \\\n",
       "443  26895  C           https://ecs.skype.com/?page=ExperimentPage&id=26895   \n",
       "\n",
       "                                            Id  \\\n",
       "443  flnps_v2_74d1be15b59a5601a2214a45e313c698   \n",
       "\n",
       "                                 SurveyId  \\\n",
       "443  265d54ad-beff-47a1-85c4-2255f0bfee1e   \n",
       "\n",
       "                                                               SurveyRatingQuestion  \\\n",
       "443  Колика је вероватноћа да ћете ову апликацију препоручити пријатељу или колеги?   \n",
       "\n",
       "    SurveyType  SurveyRating       SurveyStartDate  \\\n",
       "443  NpsStatic  5.0           2/1/2018 12:00:00 AM   \n",
       "\n",
       "                         ProcessSessionId         Platform       Product  \\\n",
       "443  517e63f0-5a39-43ed-8f08-96d8e100174e  Windows Desktop  Desktop Word   \n",
       "\n",
       "    OcvLanguage  \n",
       "443  English     "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here is an example of a data point that we are not interested in, there is no way to tell what this survey is on with respect to an office product, so we drop \n",
    "# survey responses that are ambiguous like this, again, this is only 19 surveys out of 6.3 million\n",
    "df[df['TranslatedQuestion'].str.contains('game')].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('NPS_data_separated_by_suite_and_app.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Here\n",
    "- After cleaning the dfs with the above steps, I exported a cleaned csv and imported it here, so if you are running this code from scratch, start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change working directory and import data that we cleaned with the above steps\n",
    "os.chdir('C:\\\\Users\\\\paperspace\\\\Desktop\\\\Microsoft\\\\AB Testing\\\\Logistic Regression')\n",
    "df = pd.read_csv('NPS_data_separated_by_suite_and_app.csv')\n",
    "\n",
    "#separate dfs into app and suite\n",
    "suite = df[df['NPS Tag'] == 'O365 Suite']\n",
    "app = df[df['NPS Tag'] == 'App']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6303374, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2598408, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suite.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3704966, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_significant_experiments_with_logistic_regression(df1, agg_df, product, solver = 'lbfgs'):\n",
    "        \n",
    "\n",
    "    '''\n",
    "    \n",
    "    This function takes a df with the above structure and columns. It takes this df, subsets it for a given product (exce, word, access, visio, outlook, powerpoint),    runs the data through a Random Forest Classifier and performs feature selection with the Random Forest's feature_importances_, then determines if there are any \n",
    "    linearly dependent columns (with a correlation of 1), drops those redundant features (where one experiment may be another one renamed perhaps), and finally runs\n",
    "    a logistic regression on the data to determine which experiments are significantly impacting net promoter score.\n",
    "\n",
    "    Arguments: first argument is a df that must have the structure in the above \"head\" call, second argument is a string for the name of a product (i.e. 'Word'), \n",
    "    last argument is the solver for the logistic regression which is set to Limited Memory Broyden-Fletcher-Goldfarb, the default solver in sklearn\n",
    "    \n",
    "    Output -> The output of this function is a tuple containing 1. A preliminary summery of the mode, 2. A second summary of the model (used to take columns from),\n",
    "    and 3. An output dataframe containing the significant experiment coefficients from the dataset. As such, use of this function call should be as follows:\n",
    "    \n",
    "    summary1, summary2, final_output_df = find_significant_experiments_with_logistic_regression(df, 'Word') \n",
    "    \n",
    "    *Comment lines out in first section of this code depending if you want to run analysis on Word, Powerpoint, and Excel combined or not\n",
    "\n",
    "    '''\n",
    "    \n",
    "    print(f'---->---->Running Analysis for {product}<----<----')\n",
    "    print(' ')\n",
    "    \n",
    "    #comment this line out when running analyses if you want to see only unique experiments for each product\n",
    "    df1 = df1[df1['Product'].astype(str).str.contains(f'{product}')]\n",
    "    \n",
    "    #isnert a column with all 1s for one hot encoding of experiments for each individual (the 1 will mark experiments that someone was in)\n",
    "    df1.insert(loc = 0, column = 'n', value = 1)\n",
    "    \n",
    "    #create df for logistic regression, a pivot table that has columns that are experiment IDs, df denotes whether each individual was in the experiment\n",
    "    log_df = df1.pivot_table(index=['Id'], columns = ['XpId'], values = 'n', fill_value = 0)\n",
    "    \n",
    "    #sort values of excel_df by user ID, this is to add in NPS scores for each person as a column to the log_df\n",
    "    df1 = df1.sort_values('Id').drop_duplicates(subset = 'Id')\n",
    "    \n",
    "    #add NPS score to the log_df\n",
    "    log_df['NPS'] = [x for x in df1['SurveyRating']]\n",
    "    \n",
    "    #map 0 (to denote detractors) and 1 (to denote passives and promoters) onto NPS column\n",
    "    log_df['NPS'] = log_df['NPS'].map({1:0, 2:0, 3:0, 4:1, 5:1})\n",
    "    \n",
    "    #create train/test split to feed into Random Forest, we are using this algorithm to filter out important experiments for NPS\n",
    "    X_train, X_test, y_train, y_test = train_test_split(log_df.drop('NPS', axis = 1), log_df['NPS'], test_size=0.2)\n",
    "    \n",
    "    print('Beginning Random Forest Feature Selection')\n",
    "\n",
    "#     # run gridsearch for best Random Forest params, in this case I am using RandomizedSearchCV rather than GridsearchCV, which has been shown to have similar\n",
    "#     # performance to Gridsearch, but takes significantly less time \n",
    "#     rf = RandomForestClassifier(random_state=0)\n",
    "#     param_grid = {'n_estimators': [50, 100, 250, 500, 750, 1000, 1250],#'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#                   'max_depth': [5,10,25,None]}\n",
    "#     #'oob_score': [True,False]}\n",
    "\n",
    "#     CV_rfc = RandomizedSearchCV(estimator=rf, n_jobs=-1, param_distributions=param_grid, verbose=10, scoring='neg_log_loss',cv= 5)\n",
    "#     CV_rfc.fit(X_train, y_train)\n",
    "    \n",
    "#     n_estimators, max_depth = CV_rfc.best_params_.values()\n",
    "\n",
    "\n",
    "    rfc = RandomForestClassifier(random_state = 0, n_estimators = 100, max_depth = 10, oob_score = True)\n",
    "    rfc.fit(X_train,y_train)\n",
    "    print(' ')\n",
    "    print('Scoring Random Forest on Test Data')\n",
    "    print(rfc.score(X_test,y_test))\n",
    "    \n",
    "    #getting feature importances greatest to least\n",
    "    learners = rfc.feature_importances_.argsort()[::-1]\n",
    "    \n",
    "    features = pd.DataFrame(X_train.columns[learners], rfc.feature_importances_[learners])\n",
    "    \n",
    "    #only using features that had more than .015 splits\n",
    "    features = features[features.index>0.015]\n",
    "    \n",
    "    #putting the best features into a list to use later to filter variables out of log_df\n",
    "    tree_best = features.XpId.values.tolist()\n",
    "    \n",
    "    #creating data frame containing features identified as important by Random Forest\n",
    "    X = log_df[[x for x in tree_best]]\n",
    "    \n",
    "    #insert a constant for logistic Regression\n",
    "    X.insert(loc = 0, column = 'constant', value = 1)\n",
    "    \n",
    "    #ranking columns in the dataset, there should be no tied rankings for regression to run properly\n",
    "    print(' ')\n",
    "    print('first value of each line should always be second value minus 1')\n",
    "    print(' ')\n",
    "    rank_test = X\n",
    "    for i in range(rank_test.shape[1]):\n",
    "        df_to_rank = rank_test.iloc[:,:i+1]\n",
    "        print(i,np.linalg.matrix_rank(df_to_rank))\n",
    "    print(' ')\n",
    "    \n",
    "    #redundant columns check\n",
    "    matrix = X.corr()==1\n",
    "    linear_dependents = []\n",
    "    for col in matrix.columns:\n",
    "        #print(col)\n",
    "        linear_dependents.append(list(matrix[col].index[matrix[col]==True]))\n",
    "    linear_dependents = [x for x in linear_dependents if len(x) > 1]\n",
    "    \n",
    "    #if there are linear dependents, then store them in a list and print them out in the report\n",
    "    if not linear_dependents: #evaluates whether the list contains info -- if not then print there is nothing there, same for next loop\n",
    "        print('No Linear Dependents Present')\n",
    "    else:\n",
    "        print('Here is a List of Linear Dependents:')\n",
    "        redundant_cols = [x for x in linear_dependents if len(x)>1]\n",
    "        print(redundant_cols)\n",
    "    \n",
    "    #if there are dependents then store them in a list, if not then just print a space\n",
    "    if not linear_dependents:\n",
    "        print(' ')\n",
    "    else:\n",
    "        dependents = []\n",
    "        for x in linear_dependents:\n",
    "            if len(x) > 1:\n",
    "                dependents.append(x)\n",
    "\n",
    "\n",
    "        #create a list of linearly dependent features, we are going to drop these\n",
    "        to_drop = pd.DataFrame(dependents).drop_duplicates().iloc[:,0].tolist()\n",
    "\n",
    "        #accounting for more than 2 linearly dependent columns -- should probably add in functionality for more than 3 in the future, but I have only seens 3 so far\n",
    "        a = pd.DataFrame(dependents).drop_duplicates()\n",
    "        b = a.fillna('missing')\n",
    "        second_redundant_column_out_of_3_linear_dependents = []\n",
    "        for idx, row in b.iterrows():\n",
    "            if (len(row) == 3) & ('missing' not in list(row)):\n",
    "                second_redundant_column_out_of_3_linear_dependents.append(row[1])\n",
    "\n",
    "        #extend the second out of 3 linear dependents to the \"to_drop\" list\n",
    "        to_drop.extend([col for col in second_redundant_column_out_of_3_linear_dependents])\n",
    "    \n",
    "        #drop linearly dependent features\n",
    "        X.drop(to_drop, axis = 1, inplace = True)  \n",
    "    \n",
    "        print(' ')\n",
    "        print('first value of each line should always be second value minus 1 (After Dropping Perfectly Correlated Features)')\n",
    "        print(' ')\n",
    "        \n",
    "        #perform rank test again to make sure that columns are not duplicates\n",
    "        rank_test = X\n",
    "        for i in range(rank_test.shape[1]):\n",
    "            df_to_rank = rank_test.iloc[:,:i+1]\n",
    "            print(i,np.linalg.matrix_rank(df_to_rank))\n",
    "                  \n",
    "    \n",
    "    print(' ')\n",
    "    print(f'Running Logistic Regression for {product}')\n",
    "    \n",
    "    #if we set a solver then use it\n",
    "    if solver != None:\n",
    "        \n",
    "        #instantiate Logistic Regression, print out summary\n",
    "        logit = sm.Logit(log_df['NPS'], X)\n",
    "\n",
    "        flogit = logit.fit(method = solver, maxiter = 2000) #setting max_iter high so models have a better chance of converging\n",
    "\n",
    "        summary1 = flogit.summary()\n",
    "\n",
    "        summary2 = flogit.summary2()\n",
    "    else:\n",
    "        logit = sm.Logit(log_df['NPS'], X)\n",
    "        \n",
    "        flogit = logit.fit(maxiter = 2000)\n",
    "        \n",
    "        summary1 = flogit.summary()\n",
    "        \n",
    "        summary2 = flogit.summary2()\n",
    "        \n",
    "    #I created this function to format the final table for each output, that way I only have to concatenate them at the very end\n",
    "    def make_final_table(summary2):\n",
    "        '''\n",
    "        \n",
    "        This function creates a final output table with the odds ratio, upper and lower bounds of the ratio, final probability, and lift of the experiment\n",
    "\n",
    "        Arguments: summary2 produced by the logit in the previous step\n",
    "\n",
    "        '''\n",
    "\n",
    "        #get the summary table\n",
    "        coefficients = summary2.tables[1].round(2)\n",
    "        \n",
    "        #create column for odds ratio\n",
    "        coefficients['Odds Ratio'] = np.exp(coefficients['Coef.'])\n",
    "        \n",
    "        #create column for the lower bound of the odds ratio\n",
    "        coefficients['O.R.LB'] = np.exp(pd.DataFrame(summary2.tables[1]).iloc[:, -2])\n",
    "        \n",
    "        #create column for thet upper bound of the odds ratio\n",
    "        coefficients['O.R.UP'] = np.exp(pd.DataFrame(summary2.tables[1]).iloc[:, -1])\n",
    "        \n",
    "        #grab cases that have a probability of less than.1 from the table (same threshold used in Jared's analysis)\n",
    "        coefficients = coefficients[coefficients['P>|z|'] < .1]\n",
    "        \n",
    "        #create column for the final probability\n",
    "        coefficients['FinalProbability'] = np.exp(coefficients['Coef.'].round(1)) * log_df['NPS'].value_counts(normalize = True).loc[1]\n",
    "        coefficients['FinalProbability'] = coefficients['FinalProbability'].mask(coefficients['FinalProbability'] >= 1, 0.99)\n",
    "        \n",
    "        #create column for the lift \n",
    "        coefficients['Lift'] = coefficients['FinalProbability'] - log_df['NPS'].value_counts(normalize = True).loc[1]\n",
    "\n",
    "        #return coefficient df\n",
    "        return coefficients\n",
    "\n",
    "    coefficients = make_final_table(summary2)\n",
    "        \n",
    "    summary = flogit.summary()\n",
    "    \n",
    "    def create_final_table(df2, df3, product):\n",
    "        \n",
    "        '''\n",
    "        This function creates the final formatted table, merging in treatment group sizes, product name, and treatment share out of the total flight\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        groups = df2.groupby(['XpId', 'Product']).XpGroupType.value_counts().unstack().reset_index()\n",
    "\n",
    "        same_ids = df3[df3.index != 'constant'].reset_index().rename(columns = {'index':'XpId'}).sort_values('XpId')\n",
    "\n",
    "        groups = groups[(groups['XpId'].isin(same_ids.XpId)) & (groups['Product'].str.contains(f'{product}'))].sort_values('XpId')\n",
    "\n",
    "        final_output = same_ids.merge(groups).fillna(0)\n",
    "\n",
    "        final_output['TreatmentCount'] = [x for x in final_output['T']]\n",
    "        final_output['FlightCount'] = final_output['TreatmentCount'] + final_output['C']\n",
    "        final_output.drop(['T', 'C'], axis = 1, inplace = True)\n",
    "        final_output['TreatmentShre'] = final_output['TreatmentCount'] / final_output['FlightCount']\n",
    "\n",
    "        final_output = final_output[(final_output['TreatmentCount'] > 30) & (final_output['FlightCount'] > 60)]\n",
    "    \n",
    "        return final_output\n",
    "    \n",
    "    final_output = create_final_table(agg_df, coefficients.round(2), product)\n",
    "    \n",
    "    print(' ')\n",
    "    print('---->---->Function Successfully Run<----<----')\n",
    "    print(' ')\n",
    "        \n",
    "    return summary, final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiment for EVERYTHING\n",
    "- This will take a long time, but it will end with all final dfs created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---->---->Running Analysis for Word<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.8085949764521193\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 17\n",
      "19 18\n",
      "20 19\n",
      "21 20\n",
      "22 21\n",
      "23 22\n",
      " \n",
      "Here is a List of Linear Dependents:\n",
      "[[33079, 33082], [33079, 33082], [28677, 29662], [28677, 29662]]\n",
      " \n",
      "first value of each line should always be second value minus 1 (After Dropping Perfectly Correlated Features)\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n",
      "14 15\n",
      "15 16\n",
      "16 17\n",
      "17 18\n",
      "18 19\n",
      "19 20\n",
      "20 21\n",
      "21 22\n",
      " \n",
      "Running Logistic Regression for Word\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for Excel<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.8222112606581636\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n",
      "14 15\n",
      "15 16\n",
      "16 17\n",
      "17 18\n",
      "18 19\n",
      "19 20\n",
      "20 21\n",
      " \n",
      "No Linear Dependents Present\n",
      " \n",
      " \n",
      "Running Logistic Regression for Excel\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for Powerpoint<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.8210852517075639\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      " \n",
      "Here is a List of Linear Dependents:\n",
      "[[33082, 33079], [33082, 33079]]\n",
      " \n",
      "first value of each line should always be second value minus 1 (After Dropping Perfectly Correlated Features)\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n",
      "14 15\n",
      "15 16\n",
      "16 17\n",
      "17 18\n",
      "18 19\n",
      "19 20\n",
      "20 21\n",
      " \n",
      "Running Logistic Regression for Powerpoint\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for Outlook<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.753732790382005\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 8\n",
      "10 9\n",
      "11 10\n",
      "12 11\n",
      "13 12\n",
      "14 12\n",
      "15 13\n",
      "16 14\n",
      "17 15\n",
      "18 16\n",
      "19 17\n",
      "20 18\n",
      " \n",
      "Here is a List of Linear Dependents:\n",
      "[[29662, 29661, 28677], [29662, 29661, 28677], [29662, 29661, 28677], [33082, 33079], [33082, 33079]]\n",
      " \n",
      "first value of each line should always be second value minus 1 (After Dropping Perfectly Correlated Features)\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 15\n",
      "15 16\n",
      "16 17\n",
      "17 18\n",
      " \n",
      "Running Logistic Regression for Outlook\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for OneNote<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.7826305726074267\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "23 23\n",
      "24 24\n",
      "25 25\n",
      "26 26\n",
      "27 27\n",
      " \n",
      "Here is a List of Linear Dependents:\n",
      "[[38236, 43163], [38236, 43163]]\n",
      " \n",
      "first value of each line should always be second value minus 1 (After Dropping Perfectly Correlated Features)\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n",
      "14 15\n",
      "15 16\n",
      "16 17\n",
      "17 18\n",
      "18 19\n",
      "19"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20\n",
      "20 21\n",
      "21 22\n",
      "22 23\n",
      "23 24\n",
      "24 25\n",
      "25 26\n",
      "26 27\n",
      " \n",
      "Running Logistic Regression for OneNote\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for Access<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.7194244604316546\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n",
      " \n",
      "No Linear Dependents Present\n",
      " \n",
      " \n",
      "Running Logistic Regression for Access\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for Visio<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.7323232323232324\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n",
      " \n",
      "No Linear Dependents Present\n",
      " \n",
      " \n",
      "Running Logistic Regression for Visio\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for Word<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.7779932137663597\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n",
      "14 15\n",
      "15 16\n",
      "16 17\n",
      "17 18\n",
      "18 19\n",
      "19 20\n",
      "20 21\n",
      "21 22\n",
      "22 23\n",
      "23 24\n",
      "24 25\n",
      "25 26\n",
      " \n",
      "No Linear Dependents Present\n",
      " \n",
      " \n",
      "Running Logistic Regression for Word\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for Excel<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.7972890182263747\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n",
      "14 15\n",
      "15 16\n",
      "16 17\n",
      "17 18\n",
      "18 19\n",
      "19 20\n",
      "20 21\n",
      "21 22\n",
      "22 23\n",
      "23 24\n",
      "24 25\n",
      "25 26\n",
      "26 27\n",
      "27 28\n",
      " \n",
      "No Linear Dependents Present\n",
      " \n",
      " \n",
      "Running Logistic Regression for Excel\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for Powerpoint<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.7922887756894432\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "23 23\n",
      " \n",
      "Here is a List of Linear Dependents:\n",
      "[[33082, 33079], [33082, 33079]]\n",
      " \n",
      "first value of each line should always be second value minus 1 (After Dropping Perfectly Correlated Features)\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n",
      "14 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 16\n",
      "16 17\n",
      "17 18\n",
      "18 19\n",
      "19 20\n",
      "20 21\n",
      "21 22\n",
      "22 23\n",
      " \n",
      "Running Logistic Regression for Powerpoint\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for Outlook<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.7387786553650549\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      " \n",
      "Here is a List of Linear Dependents:\n",
      "[[29662, 29661], [29662, 29661]]\n",
      " \n",
      "first value of each line should always be second value minus 1 (After Dropping Perfectly Correlated Features)\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n",
      "14 15\n",
      "15 16\n",
      "16"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17\n",
      "17 18\n",
      "18 19\n",
      " \n",
      "Running Logistic Regression for Outlook\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for OneNote<----<----\n",
      " \n",
      "Not Enough Data to Use for OneNote\n",
      "---->---->Running Analysis for Access<----<----\n",
      " \n",
      "Not Enough Data to Use for Access\n",
      "---->---->Running Analysis for Visio<----<----\n",
      " \n",
      "Not Enough Data to Use for Visio\n",
      "---->---->Running Analysis for Word<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.8234803815639181\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 12\n",
      "14 13\n",
      "15 14\n",
      "16 15\n",
      "17 16\n",
      "18 17\n",
      "19 18\n",
      "20 19\n",
      "21 20\n",
      "22 21\n",
      " \n",
      "Here is a List of Linear Dependents:\n",
      "[[28677, 29662], [28677, 29662], [33082, 33079], [33082, 33079]]\n",
      " \n",
      "first value of each line should always be second value minus 1 (After Dropping Perfectly Correlated Features)\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n",
      "14 15\n",
      "15 16\n",
      "16 17\n",
      "17 18\n",
      "18 19\n",
      "19 20\n",
      "20 21\n",
      " \n",
      "Running Logistic Regression for Word\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for Excel<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.8435236541598695\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n",
      "14 15\n",
      "15 16\n",
      "16 17\n",
      "17 18\n",
      "18 19\n",
      " \n",
      "No Linear Dependents Present\n",
      " \n",
      " \n",
      "Running Logistic Regression for Excel\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for Powerpoint<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.8351697218242008\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 12\n",
      "14 13\n",
      "15 14\n",
      "16 15\n",
      "17 16\n",
      "18 17\n",
      "19 18\n",
      "20 19\n",
      "21 20\n",
      " \n",
      "Here is a List of Linear Dependents:\n",
      "[[33082, 33079], [33082, 33079], [28677, 29662], [28677, 29662]]\n",
      " \n",
      "first value of each line should always be second value minus 1 (After Dropping Perfectly Correlated Features)\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14\n",
      "14 15\n",
      "15 16\n",
      "16 17\n",
      "17 18\n",
      "18 19\n",
      "19 20\n",
      " \n",
      "Running Logistic Regression for Powerpoint\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for Outlook<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.7590466926070039\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 3\n",
      "6 4\n",
      "7 5\n",
      "8 6\n",
      "9 7\n",
      "10 8\n",
      "11 9\n",
      "12 10\n",
      "13 11\n",
      "14 12\n",
      "15 13\n",
      "16 14\n",
      "17 15\n",
      "18 15\n",
      "19 16\n",
      "20 17\n",
      " \n",
      "Here is a List of Linear Dependents:\n",
      "[[29662, 29661, 28677], [29662, 29661, 28677], [29662, 29661, 28677], [33082, 33079], [33082, 33079]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "first value of each line should always be second value minus 1 (After Dropping Perfectly Correlated Features)\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      " \n",
      "Running Logistic Regression for Outlook\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for OneNote<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.7817248666599578\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "23 23\n",
      "24 24\n",
      "25 24\n",
      "26 25\n",
      " \n",
      "Here is a List of Linear Dependents:\n",
      "[[38236, 43163], [38236, 43163], [28677, 29662], [28677, 29662]]\n",
      " \n",
      "first value of each line should always be second value minus 1 (After Dropping Perfectly Correlated Features)\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n",
      "14 15\n",
      "15 16\n",
      "16 17\n",
      "17"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18\n",
      "18 19\n",
      "19 20\n",
      "20 21\n",
      "21 22\n",
      "22 23\n",
      "23 24\n",
      "24 25\n",
      " \n",
      "Running Logistic Regression for OneNote\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for Access<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.7050359712230215\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      " \n",
      "No Linear Dependents Present\n",
      " \n",
      " \n",
      "Running Logistic Regression for Access\n",
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "---->---->Running Analysis for Visio<----<----\n",
      " \n",
      "Beginning Random Forest Feature Selection\n",
      " \n",
      "Scoring Random Forest on Test Data\n",
      "0.7929292929292929\n",
      " \n",
      "first value of each line should always be second value minus 1\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n",
      "14 15\n",
      "15 15\n",
      " \n",
      "Here is a List of Linear Dependents:\n",
      "[[38596, 38714], [38596, 38714]]\n",
      " \n",
      "first value of each line should always be second value minus 1 (After Dropping Perfectly Correlated Features)\n",
      " \n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "9 10\n",
      "10 11\n",
      "11 12\n",
      "12 13\n",
      "13 14\n",
      "14 15\n",
      " \n",
      "Running Logistic Regression for Visio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "---->---->Function Successfully Run<----<----\n",
      " \n",
      "Wall time: 8min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "#create list oc products to iterate through\n",
    "products = ['Word', 'Excel', 'Powerpoint', 'Outlook', 'OneNote', 'Access', 'Visio']\n",
    "\n",
    "#store all results in lists, concatenate them at the end\n",
    "both_final_outputs = []\n",
    "both_summaries = []\n",
    "suite_final_outputs = []\n",
    "suite_summaries = []\n",
    "app_final_outputs = []\n",
    "app_summaries = []\n",
    "\n",
    "#run experiments for suite and app\n",
    "for product in products:\n",
    "    try:\n",
    "        summary, final_output = find_significant_experiments_with_logistic_regression(df, df, product, 'lbfgs')\n",
    "        both_final_outputs.append(final_output)\n",
    "        both_summaries.append(summary)\n",
    "    except:\n",
    "        pass\n",
    "        print(f'Not Enough Data to Use for {product}')\n",
    "\n",
    "#run experiments for suite        \n",
    "for product in products:\n",
    "    try:\n",
    "        summary, final_output = find_significant_experiments_with_logistic_regression(suite, suite, product, 'lbfgs')\n",
    "        suite_final_outputs.append(final_output)\n",
    "        suite_summaries.append(summary)\n",
    "    except:\n",
    "        pass\n",
    "        print(f'Not Enough Data to Use for {product}')\n",
    "#run experiments for app\n",
    "for product in products:\n",
    "    try:\n",
    "        summary, final_output = find_significant_experiments_with_logistic_regression(app, app, product, 'lbfgs')\n",
    "        app_final_outputs.append(final_output)\n",
    "        app_summaries.append(summary)\n",
    "    except:\n",
    "        pass\n",
    "        print(f'Not Enough Data to Use for {product}')\n",
    "        \n",
    "        \n",
    "#concatenate everything\n",
    "both_final = pd.concat(both_final_outputs, axis = 0)\n",
    "app_final = pd.concat(app_final_outputs, axis = 0)\n",
    "suite_final = pd.concat(suite_final_outputs, axis = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
